{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9140c465-b65a-4227-b8c8-3b92895b663c",
   "metadata": {},
   "source": [
    "#Time Series Analysis of ESB Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a55a63-6079-4232-a0de-f9b98c8b20c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(Rcpp)\n",
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "library(readxl)\n",
    "library(forecast)\n",
    "library(tsutils)\n",
    "\n",
    "data <- read_excel(\"data.xlsx\", col_types = c(\"skip\",\"skip\", \"skip\", \"skip\", \"numeric\"))\n",
    "data=ts(data,start = 1970, frequency = 4)\n",
    "\n",
    "autoplot(data, colour = 'black',main=\"TS Plot of ESB Connections\")\n",
    "\n",
    "ggAcf(data,main=\"ACF of Data Set\")\n",
    "ggPacf(data,main=\"PACF of Data Set\")\n",
    "\n",
    "\n",
    "data.dc <- decomp(data, outplot=1) \n",
    "residout(data.dc$irregular)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca68fd9-7736-4237-b017-695f080f0c39",
   "metadata": {},
   "source": [
    "#Divide data into test and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621e6a6b-06bc-4e62-9d97-c54888646faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train <- window(data, start=1970, end=c(2015,4), frequency=4) \n",
    "test <- window(data, start=2016, frequency=4) \n",
    "\n",
    "autoplot(train) + autolayer(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ad6437-b4de-434b-8406-0524f68283a7",
   "metadata": {},
   "source": [
    "#Box-Cox Transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc8f0bb-cafd-445e-b596-bd2205396b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(TSA)\n",
    "lambda=BoxCox.lambda(data)  #Since the lambda value is different than 1, we can say that the transformation is needed.\n",
    "lambda\n",
    "train_bc=BoxCox(train,lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e87b067-0142-48bc-aec6-4aa4a95b9abc",
   "metadata": {},
   "source": [
    "#Anomaly Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a579bc-a409-4fc3-bfac-60b399ad4663",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(chron)\n",
    "time=as.chron(train_bc)\n",
    "time1=as.Date(time,format=\"%d-%b-%y\")       #format is important.\n",
    "train_bc_anomaly=data.frame(train_bc)\n",
    "rownames(train_bc_anomaly)=time1            #Then, add time1 object as row names to data frame created for anomaly detection.\n",
    "library(anomalize)                          #tidy anomaly detection\n",
    "library(tidyverse)                          #tidyverse packages like dplyr, ggplot, tidyr\n",
    "train_bc_anomaly_ts <- train_bc_anomaly %>% rownames_to_column() %>% mutate(date = as.Date(rowname)) %>% select(-one_of('rowname'))\n",
    "train_bc_anomaly_ts <- train_bc_anomaly_ts %>% tibbletime::as_tbl_time(index = date)\n",
    "train_bc_anomaly_ts %>% time_decompose(Total, method = \"stl\", frequency = \"auto\", trend = \"auto\") %>% \n",
    "                    anomalize(remainder, method = \"gesd\", alpha = 0.05, max_anoms = 0.2) %>%  \n",
    "                    plot_anomaly_decomposition()\n",
    "\n",
    "train_bc_anomaly_ts %>%  time_decompose(Total) %>%  anomalize(remainder) %>%  time_recompose() %>%\n",
    "                    plot_anomalies(time_recomposed = TRUE, ncol = 3, alpha_dots = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44940f47-811a-4a22-a134-93b81f461971",
   "metadata": {},
   "source": [
    "#New Function That Cleans & Repairs Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99cb3d1-2c58-4bf7-86b6-7bacd7a7968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_bc_clean<-tsclean(train_bc_anomaly_ts$Total)  \n",
    "traindata_bc_clean<-ts(traindata_bc_clean,start = 1970, frequency = 4)\n",
    "autoplot(traindata_bc_clean)+autolayer(train_bc,color=\"red\")+theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde4c1b2-1c11-4f3f-ab83-8785fbf199e1",
   "metadata": {},
   "source": [
    "#Differencing Method to Make Process Stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688c3e98-074a-45a5-9c4e-b1023d9f3ff4",
   "metadata": {},
   "source": [
    "**Hegy Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23958fc6-bd26-4b20-8e4d-f5625f7b4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_bc_clean<-tsclean(train_bc_anomaly_ts$Total)  \n",
    "traindata_bc_clean<-ts(traindata_bc_clean,start = 1970, frequency = 4)\n",
    "library(pdR)\n",
    "test<-HEGY.test(traindata_bc_clean, itsd=c(1,0,c(1:3)))        #we need to take regular differencing.\n",
    "test$stats\n",
    "ndiffs(traindata_bc_clean)                                     #One difference is required to pass the stationarity tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b07c9b-4bd1-4924-8d3b-6366094f26bc",
   "metadata": {},
   "source": [
    "**Canova Hansen Test** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a62b59-25e7-4583-be2c-7c2b4feb89ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(uroot)\n",
    "ch.test(traindata_bc_clean)\n",
    "nsdiffs(traindata_bc_clean, test=\"ch\")                                           #one seasonal difference\n",
    "traindata_bc_clean_diff<-diff(traindata_bc_clean_diff, lag = 4, differences = 1) #regular and seasonal difference\n",
    "test<-HEGY.test(traindata_bc_clean_diff, itsd=c(0,0,0))     #we have no unit root problem but ACF shows a non stationary problem.      \n",
    "test$stats\n",
    "nsdiffs(traindata_bc_clean_diff, test=\"ch\", differences = 1) #we have no unit root problem \n",
    "nsdiffs(diff(traindata_bc_clean_diff, lag = 4, differences = 1))  \n",
    "autoplot(traindata_bc_clean_diff,main=\"TS Plot of Differenced Data\")+theme_minimal() #one regular and seasonal difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b9606-a69b-4877-b8fc-91540be52d9f",
   "metadata": {},
   "source": [
    "#Model Suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468ee1b3-9e2d-4f4d-b99e-d354d1259fad",
   "metadata": {},
   "source": [
    "**ACF and PACF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349f8468-3be3-46a0-ab87-fa79d459a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(gridExtra)\n",
    "library(grid)\n",
    "p1<-ggAcf(traindata_bc_clean_diff,main=\"ACF of Differenced Series\")\n",
    "p2<-ggPacf(traindata_bc_clean_diff,main=\"PACF of Differenced Series\")\n",
    "grid.arrange(p1,p2,ncol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f769d54-8d69-49eb-a0fc-d51ce044df6e",
   "metadata": {},
   "source": [
    "**Identifying Proper SARIMA Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f885037b-5a48-4f5c-b06e-c347f7c6a12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1<-Arima(traindata_bc_clean,order = c(0,1,1), seasonal = list(order=c(2,1,1), period=4), \n",
    "            method=\"ML\") \n",
    "summary(fit1)\n",
    "\n",
    "fit2<-auto.arima(traindata_bc_clean,d=1,D=1, method = \"ML\")\n",
    "summary(fit2)                                                          #best model\n",
    "\n",
    "fit3<-Arima(traindata_bc_clean,order = c(0,1,1), seasonal = list(order=c(1,1,1), period=4), \n",
    "            method=\"ML\") \n",
    "summary(fit3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb7227c-4f65-4b5b-8f2f-7c82b71061f2",
   "metadata": {},
   "source": [
    "**Diagnostic Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d7ce12-913e-4048-9594-2b965b3ef7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r=resid(fit2)                   #residuals function to extract residuals of the object.\n",
    "autoplot(r)+geom_line(y=0)+theme_minimal()+ggtitle(\"Plot of The Residuals\")\n",
    "ggAcf(traindata_bc_clean_diff,lag=48)+theme_minimal()+ggtitle(\"ACF of Stat. Series\")\n",
    "ggPacf(traindata_bc_clean_diff,lag=48)+theme_minimal()+ggtitle(\"PACF of Stat. Series\")\n",
    "\n",
    "p1=ggplot(r, aes(sample = r)) +stat_qq()+geom_qq_line()+ggtitle(\"QQ Plot of the Residuals\")+theme_minimal()\n",
    "p2=ggplot(r,aes(x=r))+geom_histogram(bins=20)+geom_density()+ggtitle(\"Histogram of Residuals\")+theme_minimal()\n",
    "p3=ggplot(r,aes(y=r,x=as.factor(1)))+geom_boxplot()+ggtitle(\"Box Plot of Residuals\")+theme_minimal()\n",
    "grid.arrange(p1,p2,p3,ncol=3)\n",
    "\n",
    "library(tseries)\n",
    "shapiro.test(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6083e80d-87d1-4535-ad1d-6c86167cedad",
   "metadata": {},
   "source": [
    "**Box-Cox Transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9488ce7-1e06-42e3-ae45-c6598e76e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(TSA)\n",
    "lambda=BoxCox.lambda(r)           #Since the lambda value is almost equal to 1, we can say that the transformation is not needed.\n",
    "lambda\n",
    "\n",
    "Box.test(r,type=\"Ljung\",lag=20)  #Portmanteau test for the null hypothesis of independence in a given time series.\n",
    "library(lmtest)\n",
    "bgtest(m,order=15) #order is up to you\n",
    "p1=ggAcf(as.vector(r),main=\"ACF of the Residuals\",lag = 48)+theme_minimal()      #to see time lags, as. factor function is used.\n",
    "p2=ggPacf(as.vector(r),main=\"PACF of the Residuals\",lag = 48)+theme_minimal()    #to see time lags, as. factor function is used.\n",
    "grid.arrange(p1,p2,ncol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b4c530-3a1c-4361-96a2-4bd0f4c19b64",
   "metadata": {},
   "source": [
    "**Homoscedasticity Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea1e33b-6b45-4b8f-ad45-b7f0c4c7496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr=r^2\n",
    "g1<-ggAcf(as.vector(rr))+theme_minimal()+ggtitle(\"ACF of Squared Residuals\")\n",
    "g2<-ggPacf(as.vector(rr))+theme_minimal()+ggtitle(\"PACF of Squared Residuals\") \n",
    "grid.arrange(g1,g2,ncol=2)\n",
    "\n",
    "library(aTSA)\n",
    "arch.test(arima(traindata_bc_clean,order = c(1,1,3), seasonal = list(order=c(0,1,1), period=4), \n",
    "                method=\"ML\"),output=TRUE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f55934-fc29-40c7-826a-dba13455620d",
   "metadata": {},
   "source": [
    "**SARIMA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dc6167-f4ec-442a-a3e6-f7d4a9a60087",
   "metadata": {},
   "outputs": [],
   "source": [
    "train <- window(data, start=1970, end=c(2015,4), frequency=4)\n",
    "test <- window(data, start=2016, frequency=4) \n",
    "forecast<-forecast::forecast(fit2,h=4)\n",
    "accuracy(forecast,test)\n",
    "\n",
    "#Back-Transformation\n",
    "lambda<-BoxCox.lambda(train)\n",
    "f_t<-InvBoxCox(forecast$mean,lambda,biasadj=TRUE,fvar = ((BoxCox(forecast$upper,lambda)\n",
    "                                                        -BoxCox(forecast$lower,lambda))/qnorm(0.975)/2)^2)\n",
    "f_u<-InvBoxCox(forecast$upper,lambda)                         #back-transformation of forecast upper\n",
    "f_l<-InvBoxCox(forecast$lower,lambda)                         #back-transformation of forecast lower\n",
    "f_tr<-InvBoxCox(fitted(forecast),lambda)                      #back-transformation of fitted forecast values\n",
    "\n",
    "accuracy(f_t,test)\n",
    "computeMASE <- function(forecast,train,test,period){\n",
    "  forecast <- as.vector(forecast)\n",
    "  train <- as.vector(train)\n",
    "  test <- as.vector(test)\n",
    "  \n",
    "  n <- length(train)\n",
    "  scalingFactor <- sum(abs(train[(period+1):n] - train[1:(n-period)])) / (n-period)\n",
    "  \n",
    "  et <- abs(test-forecast)\n",
    "  qt <- et/scalingFactor\n",
    "  meanMASE <- mean(qt)\n",
    "  return(meanMASE)\n",
    "}\n",
    "computeMASE(f_t,train,test,4)                                 #MASE function\n",
    "\n",
    "##normality test\n",
    "r<-resid(fit2)\n",
    "shapiro.test(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18b38d7-ec6a-4b7a-8852-c397588b142a",
   "metadata": {},
   "source": [
    "**ETS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cada45b1-be34-49bf-b5d3-e6f2006469ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(forecast)\n",
    "fr1<-ets(train,model=\"ZZZ\")\n",
    "autoplot(fr1)+theme_minimal()\n",
    "\n",
    "##Holt-Winterâ€™s\n",
    "fr1<-forecast::forecast(fr1,h=4)        #h represents the forecast horizons.\n",
    "fr1\n",
    "fr2=ets(train,model='MMM')\n",
    "fr2<-forecast::forecast(fr2,h=4)\n",
    "autoplot(train)+autolayer(fr1,PI=F,series=\"ETS(MAM)\")+autolayer(fr2,PI=F,series=\"ETS(MMM)\")\n",
    "                                    +ggtitle(\"Forecasts from Different ETS\")+theme_minimal()\n",
    "accuracy(fr1,test)\n",
    "accuracy(fr2,test)   #At the end, we can say that the best forecasting method ETS(MMM) according to MASE and MAPE criteria.\n",
    "summary(fr2)\n",
    "\n",
    "library(BootPR)\n",
    "##normality test\n",
    "r<-resid(fr2)\n",
    "shapiro.test(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c13db-dafc-41cc-bce5-10abf6965711",
   "metadata": {},
   "source": [
    "**PROPHET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a264805c-667e-4edb-9912-d05903875390",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(prophet)\n",
    "ds<-c(seq(as.Date(\"1970/01/01\"),as.Date(\"2015/10/01\"),by=\"quarter\"))\n",
    "head(ds)\n",
    "df<-data.frame(ds,y=as.numeric(train))\n",
    "head(df)\n",
    "\n",
    "\n",
    "train_prophet <- prophet(df,seasonality.mode = 'additive',yearly.seasonality = FALSE,weekly.seasonality = TRUE\n",
    "                                                                                     ,daily.seasonality = TRUE)\n",
    "future<-make_future_dataframe(train_prophet,periods =4,freq = \"quarter\", include_history = TRUE)\n",
    "forecast <- predict(train_prophet, future)\n",
    "accuracy(tail(forecast$yhat,4),test)\n",
    "train_prophet <- prophet(df,seasonality.mode = 'additive',yearly.seasonality = TRUE,weekly.seasonality = FALSE\n",
    "                                                                                     ,daily.seasonality = TRUE)\n",
    "future<-make_future_dataframe(train_prophet,periods =4,freq = \"quarter\", include_history = TRUE)\n",
    "forecast <- predict(train_prophet, future)\n",
    "accuracy(tail(forecast$yhat,4),test)\n",
    "train_prophet <- prophet(df,seasonality.mode = 'additive',yearly.seasonality = TRUE,weekly.seasonality = FALSE\n",
    "                                                                                    ,daily.seasonality = FALSE)\n",
    "future<-make_future_dataframe(train_prophet,periods =4,freq = \"quarter\", include_history = TRUE)\n",
    "forecast <- predict(train_prophet, future)\n",
    "accuracy(tail(forecast$yhat,4),test)\n",
    "train_prophet <- prophet(df,seasonality.mode = 'multiplicative',yearly.seasonality = TRUE,weekly.seasonality = TRUE\n",
    "                                                                                          ,daily.seasonality = TRUE)\n",
    "future<-make_future_dataframe(train_prophet,periods =4,freq = \"quarter\", include_history = TRUE)\n",
    "forecast <- predict(train_prophet, future)\n",
    "accuracy(tail(forecast$yhat,4),test)\n",
    "train_prophet <- prophet(df,seasonality.mode = 'additive',yearly.seasonality = TRUE,weekly.seasonality = TRUE\n",
    "                                                                           ,daily.seasonality = TRUE)        #best model\n",
    "\n",
    "future<-make_future_dataframe(train_prophet,periods =4,freq = \"quarter\", include_history = TRUE)\n",
    "forecast <- predict(train_prophet, future)\n",
    "forecast_t<-tail(forecast[c('ds', 'yhat', 'yhat_lower', 'yhat_upper')],4)        #test forecast\n",
    "fore<-forecast[1:184,22]                                                         #train forecast\n",
    "fore=ts(fore,start = 1970, frequency = 4)                                        #time series version of train forecast\n",
    "accuracy(tail(forecast$yhat,4),test)\n",
    "accuracy(head(forecast$yhat,184),train)\n",
    "computeMASE(tail(forecast$yhat,4),train,test,4)                                  #MASE function\n",
    "computeMASE(head(forecast$yhat,184),train,train,4)\n",
    "\n",
    "##normality test\n",
    "residuals_prophet = forecast[,22]-data\n",
    "shapiro.test(residuals_prophet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc73deb9-5e86-4cb1-abce-595c0aa45266",
   "metadata": {},
   "source": [
    "**TBATS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf89b5-7ef5-44af-a5f3-42013bf82e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbatsmodel<-tbats(train)\n",
    "tbatsmodel\n",
    "autoplot(train,main=\"TS plot of Train with TBATS Fitted\") +autolayer(fitted(tbatsmodel), series=\"Fitted\") +theme_minimal()\n",
    "tbats_forecast<-forecast::forecast(tbatsmodel,h=4,level = c(95))\n",
    "tbats_forecast\n",
    "accuracy(tbats_forecast,test)\n",
    "summary(tbats_forecast)\n",
    "\n",
    "##normality test\n",
    "shapiro.test(resid(tbatsmodel))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96deacc3-c84c-4444-b40b-c27376eb63ee",
   "metadata": {},
   "source": [
    "**NNETAR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7005b664-9fb6-4328-ab5a-04b073302a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnmodel<-nnetar(train)\n",
    "nnmodel<-nnetar(train,p=14,P=1,size=7,repeats = 50)\n",
    "nnforecast<-forecast::forecast(nnmodel,h=4,PI=TRUE,level=c(95))\n",
    "accuracy(nnforecast,test)\n",
    "nnmodel<-nnetar(train,p=13,P=2,size=7,repeats = 50)\n",
    "nnforecast<-forecast::forecast(nnmodel,h=4,PI=TRUE,level=c(95))\n",
    "accuracy(nnforecast,test)\n",
    "nnmodel<-nnetar(train,p=16,P=3,size=7,repeats = 50)\n",
    "nnforecast<-forecast::forecast(nnmodel,h=4,PI=TRUE,level=c(95))\n",
    "accuracy(nnforecast,test)\n",
    "nnmodel<-nnetar(train,p=15,P=1,size=6,repeats = 50)\n",
    "nnforecast<-forecast::forecast(nnmodel,h=4,PI=TRUE,level=c(95))\n",
    "accuracy(nnforecast,test)\n",
    "nnmodel<-nnetar(train,p=15,P=1,size=7,repeats = 20)                             \n",
    "nnforecast<-forecast::forecast(nnmodel,h=4,PI=TRUE,level=c(95))\n",
    "accuracy(nnforecast,test)\n",
    "nnmodel<-nnetar(train,p=15,P=1,size=7)\n",
    "nnforecast<-forecast::forecast(nnmodel,h=4,PI=TRUE,level=c(95))\n",
    "accuracy(nnforecast,test)\n",
    "nnmodel<-nnetar(train,p=15,P=1,size=7,repeats = 50)                             #best model\n",
    "nnforecast<-forecast::forecast(nnmodel,h=4,PI=TRUE,level=c(95))\n",
    "accuracy(nnforecast,test)\n",
    "\n",
    "summary(nnforecast)\n",
    "\n",
    "##normality test\n",
    "r<-resid(nnmodel)\n",
    "shapiro.test(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62506a89-2263-443a-a149-db0a7f8c6d17",
   "metadata": {},
   "source": [
    "#Forecast Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa69ce2-cf16-469e-bbf0-7be4e3c39ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(3,2))\n",
    "\n",
    "plot(data, flwd=1,main=\"Forecast of SARIMA\")\n",
    "lines(f_t,col=\"blue\")\n",
    "lines(f_tr,lty=2, col = \"purple\")\n",
    "lines(f_l[,2],col=\"grey\")\n",
    "lines(f_u[,2],col=\"grey\")\n",
    "abline(v = c(2016,0), col=\"red\", lwd=3, lty=1)\n",
    "legend(\"topleft\", lty=1, pch=1,cex = 0.8, col=c(1,\"purple\",\"blue\",\"grey\",\"red\"), c(\"Series\",\"Fitted values\"\n",
    "                                             ,\"Point forecast\",\"95% Prediction interval\", \"Forecast origin\"))\n",
    "segments(2016,min(f_l[,2]),2016,min(f_u[,2]), lwd=0.5, col=\"grey\", lty=2)\n",
    "segments(2016.3,f_l[2,2],2016.3,f_u[2,2], lwd=0.5, col=\"grey\", lty=2)\n",
    "segments(2016.6,f_l[3,2],2016.6,f_u[3,2], lwd=0.5, col=\"grey\", lty=2)\n",
    "segments(2016.9,max(f_l[,2]),2016.9,max(f_u[,2]), lwd=0.5, col=\"grey\", lty=2)\n",
    "#######################\n",
    "plot(data, flwd=1,main=\"Forecast of ETS\")\n",
    "lines(fr2$mean,col=\"blue\")\n",
    "lines(fitted(fr2),lty=2, col = \"purple\")\n",
    "lines(fr2$lower[,2],col=\"grey\")\n",
    "lines(fr2$upper[,2],col=\"grey\")\n",
    "abline(v = c(2016,0), col=\"red\", lwd=3, lty=1)\n",
    "legend(\"topleft\", lty=1, pch=1,cex = 0.8, col=c(1,\"purple\",\"blue\",\"grey\",\"red\"), c(\"Series\",\"Fitted values\"\n",
    "                                           ,\"Point forecast\",\"95% Prediction interval\", \"Forecast origin\"))\n",
    "segments(2016,min(fr2$lower[,2]),2016,min(fr2$upper[,2]), lwd=0.5, col=\"grey\", lty=2)\n",
    "segments(2016.3,fr2$lower[2,2],2016.3,fr2$upper[2,2], lwd=0.5, col=\"grey\", lty=2)\n",
    "segments(2016.6,fr2$lower[3,2],2016.6,fr2$upper[3,2], lwd=0.5, col=\"grey\", lty=2)\n",
    "segments(2016.9,max(fr2$lower[,2]),2016.9,max(fr2$upper[,2]), lwd=0.5, col=\"grey\", lty=2)\n",
    "######################\n",
    "plot(data, flwd=1,main=\"Forecast of PROPHET\")\n",
    "lines(forecast_t$yhat,col=\"blue\")\n",
    "lines(fore,lty=2, col = \"purple\")\n",
    "lines(forecast_t$yhat_lower,col=\"grey\")\n",
    "lines(forecast_t$yhat_upper,col=\"grey\")\n",
    "abline(v = c(2016,0), col=\"red\", lwd=3, lty=1)\n",
    "legend(\"topleft\", lty=1, pch=1,cex = 0.8, col=c(1,\"purple\",\"blue\",\"grey\",\"red\"), c(\"Series\",\"Fitted values\"\n",
    "                                            ,\"Point forecast\",\"95% Prediction interval\", \"Forecast origin\"))\n",
    "segments(2016,min(forecast_t$yhat_lower),2016,min(forecast_t$yhat_upper), lwd=0.5, col=\"grey\", lty=2)\n",
    "segments(2016.3,forecast_t$yhat_lower[2],2016.3,forecast_t$yhat_upper[2], lwd=0.5, col=\"grey\", lty=2)\n",
    "segments(2016.6,forecast_t$yhat_lower[3],2016.6,forecast_t$yhat_upper[3], lwd=0.5, col=\"grey\", lty=2)\n",
    "segments(2016.9,max(forecast_t$yhat_lower),2016.9,max(forecast_t$yhat_upper), lwd=0.5, col=\"grey\", lty=2)\n",
    "######################\n",
    "plot(data, flwd=1,main=\"Forecast of TBATS\")\n",
    "lines(tbats_forecast$mean,col=\"blue\")\n",
    "lines(fitted(tbats_forecast),lty=2, col = \"purple\")\n",
    "lines(tbats_forecast$lower,col=\"grey\")\n",
    "lines(tbats_forecast$upper,col=\"grey\")\n",
    "abline(v = c(2016,0), col=\"red\", lwd=3, lty=1)\n",
    "legend(\"topleft\", lty=1, pch=1,cex = 0.8, col=c(1,\"purple\",\"blue\",\"grey\",\"red\"), c(\"Series\",\"Fitted values\"\n",
    "                                            ,\"Point forecast\",\"95% Prediction interval\", \"Forecast origin\"))\n",
    "segments(2016,min(tbats_forecast$lower),2016,min(tbats_forecast$upper), lwd=0.5, col=\"grey\", lty=2)\n",
    "segments(2016.3,tbats_forecast$lower[2],2016.3,tbats_forecast$upper[2], lwd=0.5, col=\"grey\", lty=2)\n",
    "segments(2016.6,tbats_forecast$lower[3],2016.6,tbats_forecast$upper[3], lwd=0.5, col=\"grey\", lty=2)\n",
    "segments(2016.9,max(tbats_forecast$lower),2016.9,max(tbats_forecast$upper), lwd=0.5, col=\"grey\", lty=2)\n",
    "######################\n",
    "plot(data, flwd=1,main=\"Forecast of NNETAR\")\n",
    "lines(nnforecast$mean,col=\"blue\")\n",
    "lines(fitted(nnforecast),lty=2, col = \"purple\")\n",
    "lines(nnforecast$lower,col=\"grey\")\n",
    "lines(nnforecast$upper,col=\"grey\")\n",
    "abline(v = c(2016,0), col=\"red\", lwd=3, lty=1)\n",
    "legend(\"topleft\", lty=1, pch=1,cex = 0.8, col=c(1,\"purple\",\"blue\",\"grey\",\"red\"), c(\"Series\",\"Fitted values\"\n",
    "                                           ,\"Point forecast\",\"95% Prediction interval\", \"Forecast origin\"))\n",
    "segments(2016,min(nnforecast$lower),2016,min(nnforecast$upper), lwd=0.5, col=\"grey\", lty=2)\n",
    "segments(2016.3,nnforecast$lower[2],2016.3,nnforecast$upper[2], lwd=0.5, col=\"grey\", lty=2)\n",
    "segments(2016.6,nnforecast$lower[3],2016.6,nnforecast$upper[3], lwd=0.5, col=\"grey\", lty=2)\n",
    "segments(2016.9,max(nnforecast$lower),2016.9,max(nnforecast$upper), lwd=0.5, col=\"grey\", lty=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "conda-env-r-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
